{"title":"NB: NumPy Continued","markdown":{"headingText":"NB: NumPy Continued","containsRefs":false,"markdown":"\n\n\n\n## Quick Refresher on Shape\n\nThe **shape** of an array is represented a **tuple**, e.g. `(n, m)` for a 2D array.\n\n* The **length** of the tuple is number of **dimensions** (i.e. axes).\n* The **values** of the tuple are the number of **elements** in each dimension (axis).\n\nConsider the array `foo`:\n\nIt was created with the $2$ dimensions.\n* The first dimension, axis 0, has $6$ elements. In this case, these elements are arrays.\n* The second dimension, axis 1, has $4$ elements. Its elements are scalars (numbers in this case).\n\nThe shape of `foo[0]` is $4$. It contains $1$ axis with $4$ elements.\n\nIt has a shape of $1$ and not $4 \\times 1$ because it is a vector, not a matrix.\n\n**SO, there is a difference between a vector and a 1-column matrix.**\n\n### Reshaping\n\nIf we want to make it into a 1-column matrix, we need to reshape it using `np.reshape()`.\n\nNote that the first value of the shape argument is $-1$. This means use the length of the vector that is passed to it. \n\nWhen indexing an array, think of the **positions** of the comma-delimitted tuple as the axis.  \n\nThe **values** are the **element offsets** in the containing array. The\n\n### Example: The Normal Equation\n\nSometimes, you need to convert vectors into 1-column matrices to make certain linear algebraic functions work.\n\nConsider two random variables, $x$ and $y$. \n\nWe can fit a regression line using the **normal equation**, which appears in this week's homework.\n\n$\\begin{aligned} \\hat\\beta_i=(x^Tx)^{âˆ’1}x^Ty \\end{aligned}$ \n\nHere is a standward way of expressing it in NumPy:\n\nHowever, it will fail if we pass it our two variables, `x` and `y`.\n\nThe reason is that it expects `x` to be a matrix, since it is designed to handle n-dimension predictor variables, usually represented as $\\textbf{X}$. \n\nThe revised function will work with a vector as `x`:\n\n$\\hat\\beta_i = \\large\\frac{1}{x^Tx} \\small(x^Ty)$\n\nWe can fix the problem in the general case by converting our vector into a matrix using `np.reshape()`.\n\nOne **take-away** here is that there is a difference betweek a scalar value and a 1 x 1 array.\n\n## Broadcasting\n\nWhat happens when you try to perform an element-wise operation on two arrays of different shape?\n\nNumPy will convert a low-dimensional array into a high-dimensional array to allow the operation to take place.\n\nThis is called **broadcasting**.\n\nLet's look at at our array `foo`:\n\nIf we multiply it by 5, the scalar is converted into an array of the same shape as `foo` with the value 5 broadcast to populate the entire array.\n\nIf we want to multiply an array by a vector, the vector is broadcast to become a 2D array.\n\nNote that NumPy can't always make the adjustment:\n\n## Array-Oriented Programming\n\nUsing NumPy arrays enables you to express many kinds of data processing tasks as concise array expressions **without writing loops**. \n\nThis practice of **replacing explicit loops with array expressions** is referred to by some people as **vectorization**. \n\nVectorized array operations are often significantly **faster** than their pure Python equivalents.\n\nThey are also **visually concise and elegant**, although loops have the virtue of visualizing what's under the hood in an algorithm.\n\n## Expressing Conditional Logic as Array Operations\n\n### `np.where()`\n\nThe `np.where` function is a vectorized version of the ternary expression `x if condition else y`. \n\nSuppose we had a boolean array and two arrays of values:\n\nHere is the vectorized version:\n\n## Mathematical and Statistical Methods\n\nStatistical computations are aggregate functions apply to vectors within an array.\n\nIn a 2D array, they can be applied to rows or columns, i.e. **axis $0$ or axis $1$**.\n\nLet's create an array of random values. We can think of it is a table of observations and random variables.\n\n### `.mean()`\n\n### `.sum()`\n\nRow wise aggregration\n\nColumn-wise aggregration\n\n### `.cumsum()`\n\n## Methods for Boolean Arrays\n\n### `.sum()`\n\nSince booleans are $0$s and $1$, we can sum them to get a total truth count.\n\n### `.any()`\n\n### `.all()`\n\n## Sorting \n\n### `.sort()`\n\n## Unique and Other Set Logic\n\n### `np.unique()`\n\n### `np.in1d()`\n\nTests whether each element of a 1-D array is also present in a second array.\n\n## File Input and Output with Arrays\n\n### `np.save()`\n\nSave an array to a binary file in NumPy ``.npy`` format.\n\nAutomatically adds the `.npy` file extension.\n\n### `np.load()`\n\n### `np.savetxt()`\n\nSave an array to a text file.\n\n### `np.savez()`\n\nSave several arrays into a single file in uncompressed ``.npz`` format.\n\nClean up ...\n\n## Linear Algebra\n\n### `.dot()`\n\nDot product of two arrays. Specifically,\n- If both `a` and `b` are 1-D arrays, it is inner product of vectors\n  (without complex conjugation).\n- If both `a` and `b` are 2-D arrays, it is matrix multiplication,\n  but using `matmul()` or `a @ b` is preferred.\n- If either `a` or `b` is 0-D (scalar), it is equivalent to `multiply()`\n  and using ``numpy.multiply(a, b)`` or ``a * b`` is preferred.\n- If `a` is an N-D array and `b` is a 1-D array, it is a sum product over\n  the last axis of `a` and `b`.\n- If `a` is an N-D array and `b` is an M-D array (where `M>=2`), it is a\n  sum product over the last axis of `a` and the second-to-last axis of `b`:\n  \n```\n    dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])\n```\n\nIn NumPy, the `@` operator means [matrix multiplication](https://www.codingem.com/numpy-at-operator/).\n\n### `np.linalg.inv()`\n\n## Pseudorandom Number Generation\n\n### `np.random.normal()`\n\n### Example: Random Walks\n\nLet simulate a random walk. The walk will be represented as a vector.\n\nWe'll do it first as loop, then with vectorization.\n\n**Loops**\n\n**Vectors**\n\n### Simulating Many Random Walks at Once\n\nFeel free to experiment with other distributions for the steps other than equal-sized coin flips. You need only use a different random generator method, like standard_normal to generate normally distributed steps with some mean and standard deviation:\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":true,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"number-sections":false,"output-file":"M05-03-NumpyBasicsContinued.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.262","bibliography":["../../refs.bib"],"_quarto-vars":{"version":2,"course_num":"DS 5100","course_title":"Programming for Data Science","academic_term":"Fall 2023","cohort_type":"Online","course_code":"DS5100-2023-08-O","course_allocation":"msds_ds5100","canvas_url":"https://canvas.its.virginia.edu/courses/75059","github_url":"https://github.com/ontoligent/DS5100-2023-08-O","website_url":"https://ontoligent.github.io/DS5100-2023-08-O","survey_form_url":"https://forms.office.com/r/YWaFPXPKz8","request_form_url":"https://forms.office.com/r/7G65N5eppk"},"theme":"cosmo","fig-cap-location":"bottom","reader-mode":false},"extensions":{"book":{"multiFile":true}}}}}
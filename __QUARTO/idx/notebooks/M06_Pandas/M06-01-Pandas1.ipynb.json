{"title":"NB: Introducting Pandas","markdown":{"headingText":"NB: Introducting Pandas","containsRefs":false,"markdown":"\n\n## What is Pandas?\n\nPandas is a Python library design to work with dataframes.\n\nEssentially, it adds a ton of usability features to NumPy.\n\nIt has become a standard library in data science.\n\n## Pandas Data Frames\n\nJust as NumPy introduces the n-dimensional array as a new data structure to Python, so Pandas introduces two:\n\nThe **Series**: a 1-dimensional labeled array capable of holding any data type.\n\nThe **DataFrame**: a 2-dimensional labeled array with columns of potentially different types. \n\n<div class=\"callout\">\n\nNote: Pandas used to have a 3-dimensional structure called a **panel**, but it has been removed from the library.\n    \nIronically, the name \"pandas\" was partly derived the word \"panel\": $pan(el)-da(ta)-s$.\n    \nTo handle higher dimensional data, the Pandas team suggests using [XArray](https://xarray.pydata.org/en/stable/), which also build on NumPy arrays.\n\n</div>\n\nBy far, the most important data structure in Pandas is the dataframe (sometimes spelled \"data frame\"), with the series playing a supporting -- but crucial -- role. \n\nIn fact, dataframe objects are built out of series objects.\n\nSo, **to understand what a dataframe is and how it behaves, you need to understand what is series is and how it is constructed.**\n\nBefore going into that, here are two quick observations about dataframes:\n\n**First**, dataframes are **inspired by the R structure** of the same name. \n\nThey have many similarities, but there are fundamental differences between the two that go beyond mere language differences. \n\nMost important is the Pandas dataframes have **indexes**, whereas R dataframes do not.\n\n**Second**, it is helpful to think of Pandas as wrapper around NumPy and Matplotlib that makes it much easier to perform common operations, like select data by column name or visualizing plots. \n\nBut this comes at a cost -- Pandas is slower than NumPy. \n\nThis represents the classic trade-off between **ease-of-use** for humnas and machine **performance**.\n\n## Series Objects\n\n### Axis Labels (Indexes)\n\nA series is at heart a one-dimensional array with **labels** along its axis. \n\n* **Labels** are essentially names that, ideally, uniquely identify each row (observation).\n* It's data must be of a single type, like NumPy arrays (which they are internally).\n* The axis labels are collectively referred to as the **index**.\n\nThink of **the index as a separate data structure** that is attached to the array. \n* The array holds the data. \n* The index holds the names of the observations or things that the data are about.\n\nWhy have an index?\n\n* Indexes provide a way to access elements of the array by name.\n* They allows series objects that share index labels to be combined.\n* Many other things ...\n\nIn fact, **a dataframe is a collection of series** with a common index. \n\nTo this collection of series, the dataframe also adds a set of labels along the horizontal axis.\n* The row index is **axis 0**.\n* The column index is called **axis 1**.\n\n<div class=\"callout\">\n    The row index is usually just called the index, while the column index is call the columns.\n</div>\n\nNote that both index and column labels can be **multidimensional**.\n* The are called **Hierarchical Indexes** and go the technical name of `MultiIndexes`.\n* As an example, consider that a table of text data might have a two-column index: `(book_id, chap_id)`\n* See [the Pandas documentation](https://pandas.pydata.org/docs/user_guide/advanced.html).\n\nIt is **crucial** to understand the difference between the index of a dataframe and its data in order to understand how dataframes work.\n\nMany a headache is caused by not understanding this difference :-)\n\n**Indexes are powerful and controversial.**\n* They allow for all kinds of magic to take place when combining and accessing data.\n* But they are expensive and sometimes hard to work with (especially multiindexes).\n* They are especially difficult if you are coming from R and expecting dataframes to behave a certain way.\n\n### Some visuals to help\n\n<img src=\"https://pynative.com/wp-content/uploads/2021/02/dataframe.png\" width=\"50%\" height=\"50%\"/>\n\n<img src=\"https://miro.medium.com/max/700/1*KOBhtOeFntu6CyJUsCdN0g.jpeg\" width=\"50%\" height=\"50%\"/>\n\nBut enough introduction. \n\nLet's dive into how Pandas objects work in practice.\n\n## Importing\n\nWe import pandas like this, using the alias `pd` by convention:\n\nWe almost always import NumPy, too, since we use many of its functions with Pandas.\n\n## Data Frame Constructors\n\nThere are several ways to create pandas data frames.\n\n**Passing a dictionary of lists:**\n\n**Passing the three required pieces:**\n- columns as list\n- index as list\n- data as list of lists (2D)\n\n**Passing a list of tuples (or list-like objects):**\n\n## Naming indexes\n\nIt is helpful to name your indexes.\n\n## Copying DataFrames with `copy()`\n\nUse `copy()` to give the new df a clean break from the original.  \n\nOtherwise, the copied df will point to the same object as the original.\n\nWe create two copies, one \"deep\" and one \"shallow\".\n\nIf we alter a value in the original ...\n\n... then the shallow copy is also changed ...\n\n... while the deep copy is not.\n\nOf course, the reverse is true too -- changes to the shallow copy affect the original:\n\nSo, `df_shallow` mirrors changes to `df`, since it references its indices and data.  \n`df_deep` does not reference `df`, and so changes `to` df do not impact `df_deep`.\n\nLet's reset our dataframe.\n\n## Column Data Types\n\n### With `.types`\n\n### With `.info()`\n\n## Column Renaming\n\nCan rename one or more fields at once using a dict.  \n\nRename the field `z` to `is_label`:\n\nYou can also change column names this way:\n\n## Column Referencing\n\nPandas supports both **bracket notation** and **dot notation**.  \n\n**Bracket**\n\n**Dot** (i.e. as object attribute)\n\nDot notation is very convenient, since as object attributes they can be tab-completed in various editing environments.\n\nBut:\n- It only works if the column names are **not reserved words**.\n- It can't be used when creating a **new column** (see below).\n\nIt is convenient to names columns with a prefix, e.g. `doc_title`, `doc_year`, `doc_author`, etc. to avoid name collisions.\n\nColumn attributes and methods work with both:\n\nshow only the first value, by indexing:\n\n## Column Selection\n\nYou select columns from a dataframe by passing a value or list (or any expression that evaluates to a list).\n\nCalling a columns with a scalar returns a Series:\n\nCalling a column with a list returns a dataframe:\n\nIn Pandas, we can use \"fancy indexing\" with labels:\n\nWe can put in a list comprehension, too:\n\n## Adding New Columns\n\nIt is typical to create a new column from existing columns.  \n\nIn this example, a new column (or field) is created by summing `x` and `y`:\n\nNote the use of bracket notation on the left.\n\nWhen new columns are created, you **must** use bracket notation.\n\n## Removing Columns with `del` and `.drop()`\n\n### `del`\n\n`del` can drop a DataFrame or single columns from the frame\n\n### `.drop()`\n\nCan drop one or more columns.\n\ntakes `axis` parameter:\n- axis=0 refers to rows  \n- axis=1 refers to columns  \n\n## Load Iris Dataset\n\nLet's load a bigger data set to explore more functionality.\n\nThe function `load_dataset()` in the `seaborn` package loads the built-in dataset.\n\nCheck the data type of `iris`:\n\n### See the first and last records with `.head()` and `.tail()`\n\n### Inspect metadata\n\nshape (rows, columns):\n\nAlternatively, `len()` returns row (record) count:\n\nColumn names:\n\n### Get it all with `.info()`\n\n## The Index\n\nWe can name indexes, and it is important to do so in many cases.\n\nWe can also redefine indexes to reflect **the logic of our data**.\n\nIn this data set, the species of the flower is part of its **identity**, so it can be part of the index.\n\nThe other features vary by individual. \n\nNote that `species` is also a label that can be used for training a model to predict the species of an iris flower. In that use case, the column would be pulled out into a separate vector.\n\n## Row Selection (Filtering) \n\n### `iloc[]`\n\nYou can extract rows using **indexes** with `iloc[]`. \n\nThis fetches row 3, and all columns.\n\nfetch rows with indices 1,2 (the right endpoint is exclusive), and all columns.\n\nfetch rows with indices 1,2 and first three columns (positions 0, 1, 2)\n\n### Combining Filtering and Selecting\n\nSo, remember the **comma notation** from NumPy -- it is used here.\n\nThe first element is a **row selector**, the second a **column selector**.\n\nIn database terminology, row selection is called filtering.\n\nYou can apply slices to column names too. You don't need `.iloc[]` here.\n\n### `.loc[]`\n\nFiltering can also be done with `.loc[]`. This uses the row, column labels (names).\n\nHere we ask for rows with labels (indexes) 1-3, and it gives exactly that  \n`.iloc[]` returned rows with indices 1,2.\n\n**Author note: This is by far the more useful of the two in my experience.**\n\nNote the different behavior of the slice here -- with `.loc`, `1:3` is short-hand for `[1,2,3]`.\n\nSo, we are not using normal slicing here:\n\nAlthough this works:\n\n**Take-away:** Fancy indexing uses _new_ lists; you can use something like `[:-1]` because you are not referring to an existing list.\n\nSubset on columns with column name (as a string) or list of strings\n\nSelect all rows, specific columns\n\n### `.loc[]` with MultiIndex\n\nRecall our dataframe with a two element index:\n\nSelecting a single observation by it's key, i.e. full label:\n\nSelecting just the setosas:\n\nGrabbing one species and one feature:\n\nThis returns a series. If we want a dataframe back, we can use `.to_frame()`:\n\nWe use a tuple to index multiple index levels.\n\nNote that you can't pass slices here -- and this where indexing can get sticky.\n\n### Another Example\n\n## Boolean Filtering\n\nIt's very common to subset a dataframe based on some condition on the data.\n\nNote that even though we are filtering rows, we are not using `.loc[]` or `.iloc[]` here.\n\nPandas knows what to do if you pass a boolean structure.\n\n### Masking\n\nHere's an example of **masking** using boolean conditions passed to the dataframe selector:\n\nHere are the **values** for the feature `sepal length`:\n\nAnd here are **the boolean values** generated by applying a comparison operator to those values:\n\nThe two sets of values have the same shape.\n\nWe can now overlay the logical values over the numeric ones and keep only what is `True`:\n\n## Working with Missing Data\n\nPandas primarily uses the data type `np.nan` from NumPy to represent missing data.\n\nThese values appear as `NaN`s:\n\n### `.dropna()` \n\nThis will drop all rows with missing data in any column.\n\n[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html)\n\nThe `subset` parameter takes a list of column names to specify which columns should have missing values.\n\n### `.fillna()`\n\nThis will replace missing values with whatever you set it to, e.g. $0$s.\n\nWe can pass the results of an operation -- for example to peform **simple imputation**, we can replace missing values in each column with the median value of the respective column:\n\n## Sorting\n\n### `.sort_values()`\n\nSort by values\n- `by` parameter takes string or list of strings\n- `ascending` takes True or False\n- `inplace` will save sorted values into the df\n\n[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html)\n\n### `.sort_index()`\n\nSort by index. Example sorts by descending index\n\n## Statistics\n\n###  `describe()`\n\n### `value_counts()`\n\nThis is **a highly useful** function for showing the frequency for each distinct value.  \n\nParameters give the ability to sort by count or index, normalize, and more.  \n\n[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html)\n\nShow percentages instead of counts\n\nThe methods returns a series that can be converted into a dataframe.\n\nYou can run `.value_counts()` on a column to get a kind of histogram:\n\n### `.mean()`\n\nOperations like this generally exclude missing data.\n\nSo, it is import to convert missing data to values if they need to be considered in the denominator.\n\n### `.max()`\n\n### `.std()`\n\nThis standard deviation.\n\n### `.corr()`\n\nCorrelation can be computed on two fields by subsetting on them:\n\n## Styling\n\n## Visualization\n\nScatterplot using Seabprn on the df columns `sepal_length`, `petal_length`.\n\nVisualization will be covered separately in more detail.\n\n## Save to CSV File\n\nCommon to save df to a csv file. The full path (path + filename) is required.  \n\nThere are also options to save to a database and to other file formats, \n\nCommon optional parameters:\n- `sep` - delimiter\n- `index` - saving index column or not\n\n[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html)\n\n## Read from CSV File\n\n`read_csv()` reads from csv into DataFrame\n\ntakes full filepath\n\n[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":true,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"number-sections":false,"output-file":"M06-01-Pandas1.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.262","bibliography":["../../refs.bib"],"_quarto-vars":{"version":2,"course_num":"DS 5100","course_title":"Programming for Data Science","academic_term":"Fall 2023","cohort_type":"Online","course_code":"DS5100-2023-08-O","course_allocation":"msds_ds5100","canvas_url":"https://canvas.its.virginia.edu/courses/75059","github_url":"https://github.com/ontoligent/DS5100-2023-08-O","website_url":"https://ontoligent.github.io/DS5100-2023-08-O","survey_form_url":"https://forms.office.com/r/YWaFPXPKz8","request_form_url":"https://forms.office.com/r/7G65N5eppk"},"theme":"cosmo","fig-cap-location":"bottom","reader-mode":false},"extensions":{"book":{"multiFile":true}}}}}
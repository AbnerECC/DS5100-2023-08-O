{"title":"NB: Introducing Pandas II","markdown":{"headingText":"NB: Introducing Pandas II","containsRefs":false,"markdown":"\n\n## Set Up\n\n## Apply Lambda Functions with `.apply()`\n\nApply a transformation to each record. Uses a `lambda` function.\n\nThe `apply()` method should be used after you have established that you can't use a vectorized function.\n\nTransformation involving multiple columns. Uses `axis=1` to access columns.  \nCompute average of `sepal_length`, `sepal_width`:\n\n**Vectorized Version**\n\nCompare to `.apply()`\n\n## Aggregation\n\nInvolves one or more of:\n\n- splitting the data into groups\n- applying a function to each group\n- combining results\n\n### `.groupby()`\n\nCompute mean of each column, grouped (separately) by species\n\n### `pd.pivot_table()`\n\nApply a function `aggfunc` to selected values grouped by columns\n\n[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html)\n\nCompute mean sepal length for each species:\n\n## Stacking and Unstacking\n\nSimilar to pivoting, but requires -- and takes advantage of -- indexes.\n\n### `.unstack()`\n\n[Details](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.unstack.html)\n\nLet's look at what `unstack()` does with a dataset from Seaborn's collection.\n\nThis dataframe appears to record the results of an experiment on human attention.\n\nEach row is a trial or observation in that experiment.\n\nAn analysis of the columns in this dataframe show that `score` is a measured outcome, `subject`s are probably individuals in a comparative study where two groups, those with `attention` `divided` and those with `attention` `focused`, are subject to three different `solutions` applied to the performance of some task. `Unnamed: 0` is just the row number as index.\n\nThe purpose of the test performed in each trial seems to be see which solutions are best at overcoming divied attention in the performance of those tasks. \n\nLet's restructure our data to reflect these assumptions.\n\nWe can use `.unstack()` to provide a nice, synoptic view of these data.\n\nWe can see clearly the data from two groups by `attention`, each consisting of 10 `subject`s, each employing three solutions.\n\nBy unstacking again, we can get a sense of which solution worked best.\n\nIt appears the solution 3 performed well.\n\n### `.stack()`\n\nStack is the opposite of `.unstack()`, of course. It will project a column name series into the values of a single column.\n\n[Details](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html)\n\nLet look at this with the `taxis` database.\n\n## Combining DataFrames\n\n### `pd.concat()`  \n\nConcatenate pandas objects along an axis.\n\n[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html)\n\nCreate two dfs and vertically stack them\n\n**Concat rows**\n\n**Concat columns**\n\nThis assumes that the indexes represent IDs of specific things or events.\n\n### `.merge()`\n\nSQL-style joining of tables (DataFrames) -- although Pandas has a `.join()` method, too.\n\nImportant parameters include:\n\n- `how` : type of merge {'left', 'right', 'outer', 'inner', 'cross'}, default ‘inner’\n- `on`  : names to join on\n        \n[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)\n\nCreate two tables, `left` and `right`. Then right join them on `key`.  \nRight join means include all records from table on right.  \nThe `key` is used for matching up the records.\n\nNotice the `NaN` inserted into the record with `key='asher'`, since the left table didn't contain the key.\n\n**Matching column names**  \nIn this next example, the value columns have the same name: *val*.  Notice what happens to the column names.\n\n### `.join()`\n\nAn SQL-like joiner, but this one takes advantage of indexes.\n\nGive our dataframes indexes and distinctive columns names.\n\n[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html)\n\n### Summary\n\n* Use **join** if you have shared indexes\n* Use **merge** if you do not have shared indexes\n* Use **concat** to combine based on shared indexes or columns\n* Pay attention to resulting dataframe indexes and column names\n\n## Reshape with `.reshape()`\n\nChanges the object's shape\n\nWe illustrate creating pandas Series, extracting array of length 6, and reshaping to 3x2 array.\n\nCreate a series:\n\nExtract values:\n\nReshaping a series:\n\nIncluding -1 as one of the dimensions tells numpy: **infer** this dimension from the data and the other dimensions.\n\nExample: enforce 3 columns:\n\nEnforce 3 rows:\n\nNotice the shape of original array: `(6,)`.\n\nThis is a vector with one dimension, and is different from two-dimensional `(6,1)` array.\n\n## Categoricals\n\nCategorical data takes discrete values where computation on the values does not make sense.  \n\nZip code is a typical example.\n\nTo include categoricals in models, often they must be converted to numeric form.  \n\n### `get_dummies()`\n\nDummy code categorical data\n\nImportant parameters: \n\n- `prefix`    : append prefix to column names (a good idea for later use)\n- `drop_first`: remove first level, as only `k-1` variables needed to represent `k` levels\n\n[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)\n\nNotice `burmese` was dropped (first level by alphabet) since it can be inferred.\n\nLet's try it on the `iris` dataset.\n\nCalled `get_dummies()` by itself will handle all categoricals for you.\n\nLook at what happened to the `species` column.\n\nYou can call it one numeric columns, too.\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":true,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"number-sections":false,"output-file":"M06-02-Pandas2.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.262","bibliography":["../../refs.bib"],"_quarto-vars":{"version":2,"course_num":"DS 5100","course_title":"Programming for Data Science","academic_term":"Fall 2023","cohort_type":"Online","course_code":"DS5100-2023-08-O","course_allocation":"msds_ds5100","canvas_url":"https://canvas.its.virginia.edu/courses/75059","github_url":"https://github.com/ontoligent/DS5100-2023-08-O","website_url":"https://ontoligent.github.io/DS5100-2023-08-O","survey_form_url":"https://forms.office.com/r/YWaFPXPKz8","request_form_url":"https://forms.office.com/r/7G65N5eppk"},"theme":"cosmo","fig-cap-location":"bottom","reader-mode":false},"extensions":{"book":{"multiFile":true}}}}}